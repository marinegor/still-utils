#!/bin/bash

# TODO: add help

time=$(date "+%Y_%m_%d_%H_%M_%S")

# GENERAL PARAMETERS
PROJECT_NAME="GPCR"
NPROC="16"  # for slurm, `nproc` will be used

SLURM="1"
SLURMLINES="2000"  # it's more efficient to run more jobs than machines available
SLURMJOBS="3"  # will back up the SLURMLINES to make sure at least all machines are being used

# PEAK FINDING PARAMETERS
SNR='4.0'
THRESHOLD='30'
HIGHRES='2.5'
SHUFFLE='1'
PEAKS="peakfinder8"
INDEXING="xgandalf"
MINPEAKS="15"
OTHERPARAMS="--multi --integration=rings-grad"

GEOM="YOURGEOM.geom"
CELL="YOURCELL.cell"
LST='test.lst' # your input list

# check if path is absolute, if not -- make it
if ! [[ ${GEOM::1} == "/" ]]; then GEOM="${PWD}/${GEOM}"; fi
if ! [[ ${CELL::1} == "/" ]]; then CELL="${PWD}/${CELL}"; fi
if ! [[ ${LST::1} == "/" ]]; then LST="${PWD}/${LST}"; fi

# SLURM parameters
SLURM_HEADER_FILE="slurm.header"
SLURM_SETUP="module load apps/crystfel-0.8.0"


# Essential folders
LOGDIR="${PWD}/logs"; mkdir "${LOGDIR}" &> /dev/null
STREAMDIR="${PWD}/streams"; mkdir "${STREAMDIR}" &> /dev/null

CURRENT_LOGDIR="${LOGDIR}/${PROJECT_NAME}_${time}"
mkdir -p "${CURRENT_LOGDIR}/indexer-logs" 2>/dev/null || exit 1;


# Shuffling the stream
if [[ "$SHUFFLE" == '1' ]]; then
	shuf "$LST" > input.lst # your list must have events to enable this
	LST="input.lst";
fi


# Start building the indexamajig command
BASEEXECSTRING="indexamajig \
-g ${GEOM} \
-p ${CELL} \
--min-snr=${SNR} \
--threshold=${THRESHOLD} \
--highres=${HIGHRES} \
--temp-dir=${CURRENT_LOGDIR}/indexer-logs \
--min-peaks=${MINPEAKS} \
${OTHERPARAMS}"


if [[ "${SLURM}" == "1" ]]; then
	# Divide initial list into separate lists for each job
	NLINES_INPUT="$(wc -l ${LST})"
	if [[ "${NLINES_INPUT}" < "${SLURMLINES}" ]]; then
		split --numeric-suffixes=1 \
			--additional-suffix=".lst" \
			--suffix-length=4 \
			--number=l/${SLURMJOBS} \
			"${LST}" "${CURRENT_LOGDIR}/list_"
	else
		split --numeric-suffixes=1 \
			--additional-suffix=".lst" \
			--suffix-length=4 \
			--lines=${SLURMLINES} \
			"${LST}" "${CURRENT_LOGDIR}/list_"
	fi

	for current_lst in "${CURRENT_LOGDIR}/list_"*; do
		dummy="$(basename "${current_lst}" .lst)"
		current_idx=${dummy: -4}  # 4 is hardcoded in suffix-length in split above
		current_stream=${CURRENT_LOGDIR}/stream_${current_idx}.stream
		current_worker=${CURRENT_LOGDIR}/worker_${current_idx}.sh
		cat ${SLURM_HEADER_FILE} >> "${current_worker}"

		echo "#SBATCH --chdir ${CURRENT_LOGDIR}" >> "${current_worker}" >> ${current_worker}
		echo "#SBATCH --job-name ${PROJECT_NAME}-${current_idx}" >> ${current_worker}
		echo "#SBATCH --output ${CURRENT_LOGDIR}/stdout_${current_idx}.log" >> ${current_worker}
		echo "#SBATCH --error ${CURRENT_LOGDIR}/stderr_${current_idx}.log" >> ${current_worker}
		echo >> "${current_worker}"

		echo "${SLURM_SETUP}" >> "${current_worker}"

		# now writing the execution string itself

		EXECSTRING="${BASEEXECSTRING} -o ${current_stream} -i ${current_lst}"
		EXECSTRING="${EXECSTRING} --peaks=${PEAKS} --indexing=${INDEXING}"
		EXECSTRING="${EXECSTRING} -j \`nproc\`"  # this will use the `nproc` value on host machine
		echo "$EXECSTRING" >> "${current_worker}"

		echo "cat ${current_stream} | pylock ${STREAMDIR}/${PROJECT_NAME}_${time}.stream"
		echo "tar xzvf ${current_stream}.tar.gz ${current_stream}"

		sbatch "${current_worker}"
	done

else
	# linking the laststream
	ln -sf "streams/${PROJECT_NAME}_${time}.stream" laststream
	EXECSTRING="${BASEEXECSTRING} -o ${STREAMDIR}/${PROJECT_NAME}_${time}.stream -i ${LST}"
	EXECSTRING="${EXECSTRING} --peaks=${PEAKS} --indexing=${INDEXING}"
	EXECSTRING="${EXECSTRING} -j ${NPROC}"
	echo "$EXECSTRING"  
	eval "${EXECSTRING}" |& tee "${LOGDIR}/log.indexamajig_${time}"
fi
