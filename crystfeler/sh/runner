#!/bin/bash

HELP_STRING="\
Usage: runner input.yaml

See full documentation here: https://github.com/marinegor/still-utils
Or email marin@phystech.edu"

# reading input
if [ "$1" == "-h" ]; then
  echo "Usage: $(basename "$0") ${HELP_STRING}"
  exit 0
fi


# with courtesy to amazing @jasperes: https://github.com/jasperes/bash-yaml
#--------------------------------------------------------------------------
parse_yaml() {
    local yaml_file=$1
    local prefix=$2
    local s
    local w
    local fs

    s='[[:space:]]*'
    w='[a-zA-Z0-9_.-]*'
    fs="$(echo @|tr @ '\034')"

    (
        sed -e '/- [^\â€œ]'"[^\']"'.*: /s|\([ ]*\)- \([[:space:]]*\)|\1-\'$'\n''  \1\2|g' |

        sed -ne '/^--/s|--||g; s|\"|\\\"|g; s/[[:space:]]*$//g;' \
            -e "/#.*[\"\']/!s| #.*||g; /^#/s|#.*||g;" \
            -e "s|^\($s\)\($w\)$s:$s\"\(.*\)\"$s\$|\1$fs\2$fs\3|p" \
            -e "s|^\($s\)\($w\)${s}[:-]$s\(.*\)$s\$|\1$fs\2$fs\3|p" |

        awk -F"$fs" '{
            indent = length($1)/2;
            if (length($2) == 0) { conj[indent]="+";} else {conj[indent]="";}
            vname[indent] = $2;
            for (i in vname) {if (i > indent) {delete vname[i]}}
                if (length($3) > 0) {
                    vn=""; for (i=0; i<indent; i++) {vn=(vn)(vname[i])("_")}
                    printf("%s%s%s%s=(\"%s\")\n", "'"$prefix"'",vn, $2, conj[indent-1],$3);
                }
            }' |

        sed -e 's/_=/+=/g' |

        awk 'BEGIN {
                FS="=";
                OFS="="
            }
            /(-|\.).*=/ {
                gsub("-|\\.", "_", $1)
            }
            { print }'
    ) < "$yaml_file"
}

create_variables() {
    local yaml_file="$1"
    local prefix="$2"
    eval "$(parse_yaml "$yaml_file" "$prefix")"
}
#--------------------------------------------------------------------------

# debug flag
DEBUG="FALSE"

# merging offline by default
MERGE_OFFLINE="TRUE"

# SLURM parameters
SLURM_HEADER_FILE="slurm.header"
SLURM_SETUP="module load apps/crystfel-0.9.0"

# Essential folders
time=$(date "+%Y_%m_%d_%H_%M_%S")
LOGDIR="${PWD}/logs"; mkdir "${LOGDIR}" &> /dev/null
STREAMDIR="${PWD}/streams"; mkdir "${STREAMDIR}" &> /dev/null



TOP="none"
for var in "$@"; do
	if ! create_variables "$var"; then
		echo "Input file ${var} is invalid"; exit 1
	fi
done
TOP="$(echo -e "${TOP}" | tr -d '[:space:]')"

CURRENT_LOGDIR="${LOGDIR}/${PROJECT_NAME}_${time}"
mkdir -p "${CURRENT_LOGDIR}/indexer-logs" 2>/dev/null || exit 1;

for var in "$@"; do
	cp $var "$CURRENT_LOGDIR"
done
# check if path is absolute, if not -- make it
if ! [[ ${GEOM::1} == "/" ]]; then GEOM="${PWD}/${GEOM}"; fi
if ! [[ ${CELL::1} == "/" ]]; then CELL="${PWD}/${CELL}"; fi
if ! [[ ${LST::1} == "/" ]]; then LST="${PWD}/${LST}"; fi

# set default non-influencing SNR & THRESHOLD if cxi or h5

if [[ "$PEAKS" == "cxi" ]] || [[ "$PEAKS" == "h5" ]]; then
	SNR="0.0"
	THRESHOLD="1"
	HIGHRES="1.0"
fi

# Shuffling the stream
if   [[ "$SHUFFLE" == 1 ]] && [[ "$TOP" == "none" ]]; then
	shuf "$LST" > input.lst # your list must have events to enable this
elif [[ "$SHUFFLE" == 1 ]] && [[ "$TOP" != "none" ]]; then
	shuf "$LST" | head -n "$TOP" > input.lst
elif [[ "$SHUFFLE" == 0 ]] && [[ "$TOP" != "none" ]]; then
	head -n "$TOP" "$LST" > input.lst
elif [[ "$SHUFFLE" == 0 ]] && [[ "$TOP" == "none" ]]; then
	cat "$LST" > input.lst
fi
LST="input.lst";


# Start building the indexamajig command
BASEEXECSTRING="indexamajig \
-g ${GEOM} \
-p ${CELL} \
--min-snr=${SNR} \
--threshold=${THRESHOLD} \
--highres=${HIGHRES} \
--temp-dir="/tmp" \
--min-peaks=${MINPEAKS} \
${OTHERPARAMS}"

touch "streams/${PROJECT_NAME}_${time}.stream"
ln -sf "streams/${PROJECT_NAME}_${time}.stream" laststream
if [[ "${SLURM}" == "1" ]]; then
	NLINES_INPUT="$(wc -l ${LST} | awk '{print $1}')"
	NNODES=$(python -c "print(${NLINES_INPUT}/${NUM_WORKERS}/${NODELINES} + 1)")

	# Divide initial list into separate lists for each job
	split --numeric-suffixes=1 \
		--additional-suffix=".lst" \
		--suffix-length=4 \
		--lines=${NODELINES} \
		"${LST}" "${CURRENT_LOGDIR}/list_"

	# print headers to each worker
	for worker_num in $(seq 1 ${NUM_WORKERS}); do
		# here echo header
		current_worker=${CURRENT_LOGDIR}/worker_${worker_num}.sh
		cat ${SLURM_HEADER_FILE} >> "${current_worker}"

		echo "#SBATCH --chdir ${CURRENT_LOGDIR}" >> "${current_worker}" >> ${current_worker}
		# echo "#SBATCH --job-name ${PROJECT_NAME:0:8}_w${worker_num}" >> ${current_worker}
		echo "#SBATCH --job-name ${PROJECT_NAME:0:8}" >> ${current_worker}
		echo "#SBATCH --output ${CURRENT_LOGDIR}/stdout_${worker_num}.log" >> ${current_worker}
		echo "#SBATCH --error ${CURRENT_LOGDIR}/stderr_${worker_num}.log" >> ${current_worker}
		echo "#SBATCH --nodes ${NNODES}" >> ${current_worker}
		echo "#SBATCH --exclusive" >> ${current_worker}
		echo >> "${current_worker}"
		echo "${SLURM_SETUP}" >> "${current_worker}"
		echo >> "${current_worker}"
	done

	# writing tail line
	if [[ "${MERGE_OFFLINE}" == "FALSE" ]]; then
		worker_num=0
		for current_lst in "${CURRENT_LOGDIR}/list_"*; do
			dummy="$(basename "${current_lst}" .lst)"
			current_idx=${dummy: -4}  # 4 is hardcoded in suffix-length in 'split' command above
			worker_num=$(( worker_num % NUM_WORKERS + 1))
			current_stream=${CURRENT_LOGDIR}/stream_${current_idx}.stream
			current_worker=${CURRENT_LOGDIR}/worker_${worker_num}.sh
		
			echo "touch ${current_stream}" >> "${current_worker}"
			echo "tail -f ${current_stream} --pid=\$\$ | pylock ${STREAMDIR}/${PROJECT_NAME}_${time}.stream & disown" >> "${current_worker}"

		done
	fi

	# writing multiple-worker execution strings
	worker_num=0
	for current_lst in "${CURRENT_LOGDIR}/list_"*; do
		dummy="$(basename "${current_lst}" .lst)"
		current_idx=${dummy: -4}  # 4 is hardcoded in suffix-length in 'split' command above
		worker_num=$(( worker_num % NUM_WORKERS + 1))
		current_stream=${CURRENT_LOGDIR}/stream_${current_idx}.stream
		current_worker=${CURRENT_LOGDIR}/worker_${worker_num}.sh

		# now writing the execution string itself
		EXECSTRING="srun --exclusive --nodes=1 -c ${NPROC} --ntasks 1 ${BASEEXECSTRING} -o ${current_stream} -i ${current_lst}"
		EXECSTRING="${EXECSTRING} --peaks=${PEAKS} --indexing=${INDEXING}"
		EXECSTRING="${EXECSTRING} -j ${NPROC}"  # this will use the `nproc` value on host machine

		echo "$EXECSTRING &" >> "${current_worker}"

		# echo "cat ${current_stream} | pylock ${STREAMDIR}/${PROJECT_NAME}_${time}.stream.final" >> "${current_worker}"
		# targz partial streams to save some space
		# echo "tar fcz ${current_stream}.tar.gz ${current_stream} --absolute-names" >> "${current_worker}"
	done

	# modifying node numbers and running sbatch-ing workers
	for worker in "${CURRENT_LOGDIR}/worker_"*; do
		echo "wait" >> "${worker}"
		cat "${worker}" | sed "s/SBATCH --nodes ${NNODES}/SBATCH --nodes $(cat ${worker} | grep srun | wc -l)/g" > "${CURRENT_LOGDIR}/tmp_worker.sh"
		cp "${CURRENT_LOGDIR}/tmp_worker.sh" "${worker}"
		rm "${CURRENT_LOGDIR}/tmp_worker.sh"
		if [[ "${DEBUG}" == "FALSE" ]]; then
			JOB_NUMBERS="${JOB_NUMBERS} $(sbatch "${worker}" | awk '{ print $4 }')"
		else
			JOB_NUMBERS="${JOB_NUMBERS} $(echo "$worker" | awk '{print substr($0,length($0)-3,1)}')" # make e.g 2 from worker_2.sh
		fi
	done

	echo "Job numbers submitted are ${JOB_NUMBERS}"

	if [[ "${MERGE_OFFLINE}" == "TRUE" ]]; then

		merger=${CURRENT_LOGDIR}/merger.sh
		cat ${SLURM_HEADER_FILE} >> "${merger}"
		echo "#SBATCH --chdir ${CURRENT_LOGDIR}" >> "${merger}" >> ${merger}
		echo "#SBATCH --job-name ${PROJECT_NAME:0:8}" >> ${merger}
		echo "#SBATCH --output ${CURRENT_LOGDIR}/stdout_merge.log" >> ${merger}
		echo "#SBATCH --error ${CURRENT_LOGDIR}/stderr_merge.log" >> ${merger}
		echo "#SBATCH --ntasks=1" >> ${merger}
		echo "#SBATCH --cpus-per-task=1" >> ${merger}

		dep_string="#SBATCH --dependency=afterany"
		for job_number in ${JOB_NUMBERS}; do
			dep_string="${dep_string}:${job_number}"
		done

		echo "${dep_string}" >> ${merger}
		echo >> "${merger}"

		echo "for strm in \"${CURRENT_LOGDIR}/stream_*.stream\"; do
			echo \"Found \${strm}\"
			cat \${strm} >> ${STREAMDIR}/${PROJECT_NAME}_${time}.stream
		done" >> "${merger}"
		
		if [[ "${DEBUG}" == "FALSE" ]]; then
			sbatch "${merger}"
		fi
	fi

	echo "tail -f ${CURRENT_LOGDIR}/stderr_*.log"

else
	# linking the laststream
	EXECSTRING="${BASEEXECSTRING} -o ${STREAMDIR}/${PROJECT_NAME}_${time}.stream -i ${LST}"
	EXECSTRING="${EXECSTRING} --peaks=${PEAKS} --indexing=${INDEXING}"
	EXECSTRING="${EXECSTRING} -j ${NPROC}"
	echo "$EXECSTRING"  
	eval "${EXECSTRING}" |& tee "${LOGDIR}/log.indexamajig_${time}"
fi
