#!/bin/sh

# Split a large indexing job into many small tasks and submit using SLURM

# ./turbo-index my-files.lst label my.geom /location/for/streams

# Copyright Â© 2016-2017 Deutsches Elektronen-Synchrotron DESY,
#                       a research centre of the Helmholtz Association.
#
# Authors:
#   2016      Steve Aplin <steve.aplin@desy.de>
#   2016-2017 Thomas White <taw@physics.org>

SPLIT=200  # Size of job chunks
MAIL=you@example.org  # Email address for SLURM notifications

INPUT="On_full.lst"
INPUT="On_existing.lst"
RUN=kr2_$(date +%F-%H-%M-%S)
GEOM="${PWD}/last_3.12-predrefine.geom"
STREAMDIR="/home/common/marin.ev/slowhome/PAL_data/proc/marinegor/kr2/streams"
CELL="c222_v4.cell" 

# Set up environment here if necessary
module load apps/crystfel-0.8.0

# Generate event list from file above
list_events -i $INPUT -g $GEOM -o events-${RUN}.lst
if [ $? != 0 ]; then
    echo "list_events failed, assuming this is already listed"
    shuf $INPUT > events-${RUN}.lst
fi

# Count total number of events
wc -l events-${RUN}.lst

# # Split the events up, will create files with $SPLIT lines
split -a 3 -d -l $SPLIT events-${RUN}.lst split-events-${RUN}.lst
mv split-events-${RUN}.lst* splits

# # Clean up
rm -f events-${RUN}.lst

# Loop over the event list files, and submit a batch job for each of them
for FILE in splits/split-events-${RUN}.lst*; do

    # Stream file is the output of crystfel
    STREAM=`echo $FILE | sed -e "s/splits\/split-events-${RUN}.lst/${RUN}.stream/"`

    # Job name
    NAME=`echo $FILE | sed -e "s/splits\/split-events-${RUN}.lst/${RUN}-/"`

    # Job number
    NUMBER=${NAME##$RUN-}
    POS=`expr $NUMBER \* $SPLIT + 1`

    echo "$NAME (serial start $POS): $FILE  --->  $STREAM"

    SLURMFILE="shs/${NAME}.sh"

    echo "#!/bin/sh" > $SLURMFILE
    echo >> $SLURMFILE

    echo "#SBATCH --partition=RT" >> $SLURMFILE  # Set your partition here
    echo "#SBATCH --time=01:00:00" >> $SLURMFILE
    echo "#SBATCH --nodes=1" >> $SLURMFILE
    echo "#SBATCH --cpus-per-task=16" >> $SLURMFILE
    echo "#SBATCH --nice=100" >> $SLURMFILE # Set priority very low to allow other jobs through
    echo >> $SLURMFILE

    echo "#SBATCH --chdir   $PWD" >> $SLURMFILE
    echo "#SBATCH --job-name  $NAME" >> $SLURMFILE
    echo "#SBATCH --output    logs/$NAME-%N-%j.out" >> $SLURMFILE
    echo "#SBATCH --error     logs/$NAME-%N-%j.err" >> $SLURMFILE
    echo "#SBATCH --comment   'crystfel job for LPIMB'" >> "$SLURMFILE"
    echo >> $SLURMFILE

    echo "module load apps/crystfel-0.8.0" >> $SLURMFILE  # Set up environment here (again) if necessary
    echo >> $SLURMFILE

    command="indexamajig -i $FILE -o $STREAMDIR/$STREAM --serial-start=$POS"
    command="$command -j \`nproc\` -g $GEOM"
    command="$command --peaks=peakfinder8 -p ${CELL} --multi --min-peaks=10"
    command="$command --min-res=25 --max-res=310 --multi"
    command="$command --threshold=50 --min-snr=3.0 --highres=2.2"
    command="$command --indexing=asdf,xds,mosflm,taketwo,felix"
    command="$command --temp-dir=logs"

    echo $command >> $SLURMFILE

    sbatch $SLURMFILE

done


# echo "Warning: running cleanup!"
# for FILE in split-events-${RUN}.lst*; do
#     NAME=`echo $FILE | sed -e "s/split-events-${RUN}.lst/${RUN}-/"`
#     NUMBER=${NAME##$RUN-}
#     POS=`expr $NUMBER \* $SPLIT + 1`
#     SLURMFILE="${NAME}.sh"
#     rm "$NAME"
#     rm "$SLURMFILE"
# done

